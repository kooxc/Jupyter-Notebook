{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOPHX2Kb+5wVjUV6f6u2GW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kooxc/Jupyter-Notebook/blob/main/langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 一、安装"
      ],
      "metadata": {
        "id": "1nUvpK8nGb-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看当前kernel下已安装的包  list packages\n",
        "!pip list --format=columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5v2D_OpEGlBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装 langchain 包\n",
        "!pip install langchain\n",
        "!pip install langchain-core\n",
        "!pip install langchain-community\n",
        "!pip install langchain-openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VbFnfYFwGpOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装阿里通义千问的包\n",
        "!pip install dashscope"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G2as_uL1GqGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 二、基本调用示例"
      ],
      "metadata": {
        "id": "kwooEjRBIW04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1、使用ChatTongyi访问"
      ],
      "metadata": {
        "id": "GMbWPBo_STTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.llms import ChatTongyi\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"DASHSCOPE_API_KEY\"] = userdata.get('QWEN_KEY')\n",
        "\n",
        "llm = ChatTongyi(model=\"qwen-turbo\")\n",
        "llm.invoke(\"50个字介绍一下明源云这家公司?\")"
      ],
      "metadata": {
        "id": "Kuw-J2CwIfXF",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ea6be21-5670-40e9-a46a-13122ae55c99"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'明源云是一家专注于不动产领域的数字化解决方案提供商，致力于为房地产企业及上下游生态链提供全生命周期的数字化产品与服务，助力行业转型升级，提升运营效率与客户体验。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2、使用ChatOpenAI访问"
      ],
      "metadata": {
        "id": "rps-ZLjeShEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model=\"qwen-turbo\",\n",
        "    base_url=userdata.get('QWEN_BASE'),\n",
        "    openai_api_key= userdata.get('QWEN_KEY')\n",
        ")\n",
        "llm.invoke(\"50个字介绍一下明源云这家公司?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "BAMba8paSgcT",
        "outputId": "118bdfb6-be99-4a1b-f9f7-8949ce4cf2a1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'convert_to_openai_image_block' from 'langchain_core.messages' (/usr/local/lib/python3.11/dist-packages/langchain_core/messages/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-be1898b745a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m llm = ChatOpenAI(\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"qwen-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QWEN_BASE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mopenai_api_key\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QWEN_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureOpenAIEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mazure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ChatOpenAI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AzureChatOpenAI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/azure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0;31m from langchain_core.messages import (\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mAIMessageChunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'convert_to_openai_image_block' from 'langchain_core.messages' (/usr/local/lib/python3.11/dist-packages/langchain_core/messages/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 三、聊天模型"
      ],
      "metadata": {
        "id": "guFf6YLELCCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models.tongyi import ChatTongyi\n",
        "llm = ChatTongyi(model=\"qwen-turbo\")"
      ],
      "metadata": {
        "id": "EtKAUnOwKbKi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1、格式化输出"
      ],
      "metadata": {
        "id": "gtuOt4BwL3Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# 定义Pydantic模型\n",
        "class Company(BaseModel):\n",
        "    \"\"\"公司简介信息\"\"\"\n",
        "\n",
        "    domain: str = Field(description=\"官方域名地址\")\n",
        "    business: str = Field(description=\"主营业务\")\n",
        "    boss: str = Field(description=\"老板\")\n",
        "    income: str = Field(description=\"最近市场披露的收入\")\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(Company)\n",
        "structured_llm.invoke(\"介绍一下明源云这家公司\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "584baDrkLIuT",
        "outputId": "6c0871da-4e64-4085-9f37-6c7748e14209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Company(domain='www.mingyuanyun.com', business='房地产行业数字化转型解决方案提供商', boss='高宇', income='2022年收入超过10亿元')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2、工具模式"
      ],
      "metadata": {
        "id": "Wy7yUqsxLrEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 函数名、类型和文档注释都是该工具的一部分\n",
        "# 传递给模型的模式，定义良好的描述性模式，是提示工程的扩展，是使模型性能良好的重要组成部分\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers.\n",
        "\n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers.\n",
        "\n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "tools = [add, multiply]"
      ],
      "metadata": {
        "id": "c-wxHx9wLxQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "query = \"3 * 12 = ？\"\n",
        "\n",
        "llm_with_tools.invoke(query)"
      ],
      "metadata": {
        "id": "h1Ad8GEaMpCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3、缓存\n",
        "在 LangChain 中，set_llm_cache 是一个用于设置缓存机制的函数。它的主要作用是通过缓存来减少对语言模型（LLM）的重复调用，从而节省时间和计算资源。以下是它的具体作用和使用场景：\n",
        "\n",
        "**缓存的作用**\n",
        "\n",
        "减少重复调用：如果相同的输入多次发送到 LLM，缓存可以存储之前的结果，避免重复调用模型，从而提高效率。\n",
        "节省成本和时间：LLM 的调用通常需要消耗计算资源和时间，缓存可以显著减少这些开销。\n",
        "提高性能：通过缓存，程序可以更快地获取结果，尤其是在需要频繁调用 LLM 的场景中。\n",
        "\n",
        "**如何使用 set_llm_cache**\n",
        "\n",
        "set_llm_cache 是 LangChain 提供的一个全局设置函数，用于启用缓存机制。它通常与 LangChain 的缓存实现（如 InMemoryCache 或 SQLiteCache）一起使用。"
      ],
      "metadata": {
        "id": "4LwkZxt_M-jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from langchain_core.caches import InMemoryCache\n",
        "from langchain_core.globals import set_llm_cache\n",
        "\n",
        "\n",
        "set_llm_cache(InMemoryCache())\n",
        "llm.invoke(\"50个字以内介绍一下明源云这家公司\")"
      ],
      "metadata": {
        "id": "ryTdQo0JNA8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#再次调用\n",
        "\n",
        "llm.invoke(\"50个字以内介绍一下明源云这家公司\")"
      ],
      "metadata": {
        "id": "_ovE6-V_NLqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4、对话消息\n",
        "- SystemMessage: 描述问题的背景,或者描述大模型的角色\n",
        "- HumanMessage: 用户输入的问题\n",
        "- AIMessage: 大模型输入的答案，另外还有一种消息是function_call"
      ],
      "metadata": {
        "id": "MufYIArDlloZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage,AIMessage\n",
        "\n",
        "message=[\n",
        "    SystemMessage(\"你想了解哪个公司信息，我可以在50个字以内介绍这家公司\"),\n",
        "    HumanMessage(\"明源云\")\n",
        "]\n",
        "llm.invoke(message)\n",
        "\n",
        "#其他多种调用方式：\n",
        "# llm.invoke([{'role':'user','content':'用友'}])"
      ],
      "metadata": {
        "id": "hwF5Wgg1lp9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "其他多种调用方式："
      ],
      "metadata": {
        "id": "WIIpxecPrZ9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke([\n",
        "    {'role':'system','content':'你想了解哪个公司信息，我可以在50个字以内介绍这家公司'},\n",
        "     {'role':'user','content':'用友'}\n",
        "])"
      ],
      "metadata": {
        "id": "seN0njbvrYYh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}